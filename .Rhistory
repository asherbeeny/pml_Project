#     }
#   }
}
output <- data.frame(output)
class(output)
dim(output)
table(output)
iterations = 67593#227571
variables = 2
output <- matrix(ncol=variables, nrow=iterations)
for(i in 1:iterations){
if(i <= 67593)
{
output [i,1] = 'Rosi'
if(i <= 2593)
{
print(i)
analysis [i,2] =1
}
else
{
output [i,2] =0
}
}
#   if(i > 67593)
#   {
#     output [i,1] = 'Piog'
#     if(i <= 61979)
#     {
#       output [i,2] =1
#     }
#     else
#     {
#       output [i,2] =0
#     }
#   }
}
output <- data.frame(output)
class(output)
dim(output)
table(output)
iterations = 67593#227571
variables = 2
output <- matrix(ncol=variables, nrow=iterations)
for(i in 1:iterations)
{
if(i <= 67593)
{
output [i,1] = 'Rosi'
if(i <= 2593)
{
analysis [i,2] =1
}
else
{
print(i)
output [i,2] =0
}
}
#   if(i > 67593)
#   {
#     output [i,1] = 'Piog'
#     if(i <= 61979)
#     {
#       output [i,2] =1
#     }
#     else
#     {
#       output [i,2] =0
#     }
#   }
}
output <- data.frame(output)
class(output)
dim(output)
table(output)
iterations = 67593#227571
variables = 2
output <- matrix(ncol=variables, nrow=iterations)
for(i in 1:iterations)
{
if(i <= 67593)
{
if(i <= 2593)
{
analysis [i,2] =1
output [i,1] = 'Rosi'
}
else
{
print(i)
output [i,2] =0
output [i,1] = 'Rosi'
}
}
#   if(i > 67593)
#   {
#     output [i,1] = 'Piog'
#     if(i <= 61979)
#     {
#       output [i,2] =1
#     }
#     else
#     {
#       output [i,2] =0
#     }
#   }
}
output <- data.frame(output)
class(output)
dim(output)
table(output)
iterations = 67593#227571
variables = 2
output <- matrix(ncol=variables, nrow=iterations)
for(i in 1:iterations)
{
if(i <= 67593)
{
if(i <= 2593)
{
analysis [i,2] =1
output [i,1] = 'Hamada'
}
else
{
output [i,2] =0
output [i,1] = 'Rosi'
}
}
#   if(i > 67593)
#   {
#     output [i,1] = 'Piog'
#     if(i <= 61979)
#     {
#       output [i,2] =1
#     }
#     else
#     {
#       output [i,2] =0
#     }
#   }
}
output <- data.frame(output)
class(output)
dim(output)
table(output)
output[1,1]
output[1,2]
clinical.trial <-
data.frame(patient = 1:100,
age = rnorm(100, mean = 60, sd = 6),
treatment = gl(2, 50,
labels = c("Treatment", "Control")),
center = sample(paste("Center", LETTERS[1:5]), 100, replace = TRUE))
head(clinical.trial)
table(clinical.trial)
table(clinical.trial$center)
iterations = 67593#227571
variables = 2
output <- matrix(ncol=variables, nrow=iterations)
for(i in 1:iterations)
{
if(i <= 67593)
{
if(i <= 2593)
{
analysis [i,2] =1
output [i,1] = 'Rosi'
}
else
{
output [i,2] =0
output [i,1] = 'Rosi'
}
}
if(i > 67593)
{
output [i,1] = 'Piog'
if(i <= 61979)
{
output [i,2] =1
}
else
{
output [i,2] =0
}
}
}
output <- data.frame(output)
class(output)
dim(output)
table(output)
output[1,2]
iterations = 227571
variables = 2
output <- matrix(ncol=variables, nrow=iterations)
for(i in 1:iterations)
{
if(i <= 67593)
{
if(i <= 2593)
{
analysis [i,2] =1
output [i,1] = 'Rosi'
}
else
{
output [i,2] =0
output [i,1] = 'Rosi'
}
}
if(i > 67593)
{
output [i,1] = 'Piog'
if(i <= 61979)
{
output [i,2] =1
}
else
{
output [i,2] =0
}
}
}
output <- data.frame(output)
class(output)
dim(output)
table(output)
output[1,2]
table(output$X1)
table(output$X2)
iterations = 227571
variables = 2
output <- matrix(ncol=variables, nrow=iterations)
for(i in 1:iterations)
{
if(i <= 67593)
{
if(i <= 2593)
{
analysis [i,2] ='1'
output [i,1] = 'Rosi'
}
else
{
output [i,2] ='0'
output [i,1] = 'Rosi'
}
}
if(i > 67593)
{
output [i,1] = 'Piog'
if(i <= 61979)
{
output [i,2] ='1'
}
else
{
output [i,2] ='0'
}
}
}
output <- data.frame(output)
class(output)
dim(output)
table(output$X2)
output[1,2]
table(output)
iterations = 227571
variables = 2
output <- matrix(ncol=variables, nrow=iterations)
for(i in 1:iterations)
{
if(i <= 67593)
{
if(i <= 2593)
{
analysis [i,2] ='hamada'
output [i,1] = 'Rosi'
}
else
{
output [i,2] ='tarek'
output [i,1] = 'Rosi'
}
}
if(i > 67593)
{
output [i,1] = 'Piog'
if(i <= 61979)
{
output [i,2] ='ali'
}
else
{
output [i,2] ='kakak'
}
}
}
output <- data.frame(output)
class(output)
dim(output)
table(output)
output[1,2]
iterations = 227571
variables = 2
output <- matrix(ncol=variables, nrow=iterations)
for(i in 1:iterations)
{
if(i <= 67593)
{
if(i <= 2593)
{
analysis [i,2] ='hamada'
output [i,1] = 'Rosi'
}
else
{
output [i,2] ='tarek'
output [i,1] = 'salsa'
}
}
if(i > 67593)
{
output [i,1] = 'Piog'
if(i <= 61979)
{
output [i,2] ='ali'
}
else
{
output [i,2] ='kakak'
}
}
}
output <- data.frame(output)
class(output)
dim(output)
table(output)
output[1,2]
install.packages("RGtk2")
library (rpart)
library (caret)
library(ggplot2)
library (caret)
library (randomForest)
#download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "Data/pml-training.csv")
#download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "Data/pml-testing.csv")
setwd("C:/Sherbeeny/Workspace/R/DataScience-Coursera/ML-Project")
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "Data/pml-training.csv")
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "Data/pml-testing.csv")
# Load the data from downloaded CSV files
setwd("C:/Sherbeeny/Workspace/R/DataScience-Coursera/ML-Project")
# Load the data from downloaded CSV files
pml_train <- read.csv('Data/pml-training.csv', na.strings=c("NA","#DIV/0!", ""))
pml_test <- read.csv('Data/pml-testing.csv' , na.strings=c("NA","#DIV/0!", ""))
head(pml_train)
dim(pml_train)
dim(pml_test)
names(pml_train)
# Data Munging
#remove features that don't have many missing values but have one unique value
#(i.e. zero variance predictors) or have few unique values relative to the number of samples and the
#ratio of frequency of the most common value to the frequency of second most common value is large.
bad_Columns <- nearZeroVar(pml_train, saveMetrics = TRUE)
bad_Columns$nzv
pml_train <- pml_train[, bad_Columns$nzv==FALSE]
#Same for Testing dataset
pml_test <- pml_test[, bad_Columns$nzv==FALSE]
dim(pml_train)
#Similarly the user and time information should not have any effect on
#whether barbell lifts are performed correctly or not.
unnecessary_cols <- c("user_name", "raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp")
for (col in unnecessary_cols) {
pml_train[, col] <- NULL
pml_test[, col] <- NULL
}
dim(pml_train)
# Delete columns with all missing values
pml_train<-pml_train[,colSums(is.na(pml_train)) == 0]
pml_test <-pml_test[,colSums(is.na(pml_test)) == 0]
dim(pml_train)
names(pml_train)
pml_train$X <- NULL
pml_test$X <- null
pml_test$X <- Null
pml_test$X <- NULL
dim(pml_train)
names(pml_train)
inTrain <- createDataPartition(y=trainingset$classe, p=0.75, list=FALSE)
inTrain <- createDataPartition(y=pml_train$classe, p=0.75, list=FALSE)
pml_train <- pml_train[inTrain, ]
pml_valid <- pml_train[-inTrain, ]
<- read.csv('Data/pml-training.csv', na.strings=c("NA","#DIV/0!", ""))
pml_test <- read.csv('Data/pml-testing.csv' , na.strings=c("NA","#DIV/0!", ""))
head(pml_train)
dim(pml_train)
dim(pml_test)
names(pml_train)
# Data Munging
#remove features that don't have many missing values but have one unique value
#(i.e. zero variance predictors) or have few unique values relative to the number of samples and the
#ratio of frequency of the most common value to the frequency of second most common value is large.
bad_Columns <- nearZeroVar(pml_train, saveMetrics = TRUE)
bad_Columns$nzv
pml_train <- pml_train[, bad_Columns$nzv==FALSE]
#Same for Testing dataset
pml_test <- pml_test[, bad_Columns$nzv==FALSE]
dim(pml_train)
#Similarly the user and time information should not have any effect on
#whether barbell lifts are performed correctly or not.
unnecessary_cols <- c("user_name", "raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp")
for (col in unnecessary_cols) {
pml_train[, col] <- NULL
pml_test[, col] <- NULL
}
dim(pml_train)
# Delete columns with all missing values
pml_train<-pml_train[,colSums(is.na(pml_train)) == 0]
pml_test <-pml_test[,colSums(is.na(pml_test)) == 0]
pml_train$X <- NULL
pml_test$X <- NULL
dim(pml_train)
#Build the model
set.seed(234334)
inTrain <- createDataPartition(y=pml_train$classe, p=0.75, list=FALSE)
training <- pml_train[inTrain, ]
validation <- pml_train[-inTrain, ]
pml_train <- read.csv('Data/pml-training.csv', na.strings=c("NA","#DIV/0!", ""))
pml_test <- read.csv('Data/pml-testing.csv' , na.strings=c("NA","#DIV/0!", ""))
head(pml_train)
dim(pml_train)
dim(pml_test)
names(pml_train)
# Data Munging
#remove features that don't have many missing values but have one unique value
#(i.e. zero variance predictors) or have few unique values relative to the number of samples and the
#ratio of frequency of the most common value to the frequency of second most common value is large.
bad_Columns <- nearZeroVar(pml_train, saveMetrics = TRUE)
bad_Columns$nzv
pml_train <- pml_train[, bad_Columns$nzv==FALSE]
#Same for Testing dataset
pml_test <- pml_test[, bad_Columns$nzv==FALSE]
dim(pml_train)
#Similarly the user and time information should not have any effect on
#whether barbell lifts are performed correctly or not.
unnecessary_cols <- c("user_name", "raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp")
for (col in unnecessary_cols) {
pml_train[, col] <- NULL
pml_test[, col] <- NULL
}
dim(pml_train)
# Delete columns with all missing values
pml_train<-pml_train[,colSums(is.na(pml_train)) == 0]
pml_test <-pml_test[,colSums(is.na(pml_test)) == 0]
pml_train$X <- NULL
pml_test$X <- NULL
dim(pml_train)
#Build the model
set.seed(234334)
inTrain <- createDataPartition(y=pml_train$classe, p=0.75, list=FALSE)
training <- pml_train[inTrain, ]
validation <- pml_train[-inTrain, ]
obs <- c()
preds <- []
for(i in 1:10) {
intrain = sample(1:dim(train_data)[1], size=dim(train_data)[1] * 0.8, replace=F)
train_cross = train_data[intrain,]
test_cross = train_data[-intrain,]
rf <- randomForest(classe ~ ., data=train_cross)
obs <- c(obs, test_cross$classe)
preds <- c(preds, predict(rf, test_cross))
}
dim(validation)
dim(training)
dim(pml_test)
model1 <- rpart(classe ~ ., data=training, method="class")
model1 <- rpart(classe ~ ., data=training, method="rf")
model1 <- rpart(classe ~ ., data=training, method="gbm")
model1 <- rpart(classe ~ ., data=training, method="glm")
library (caret)
model1 <- rpart(classe ~ ., data=training, method="glm")
model1 <- rpart(classe ~ ., data=training, method="class")
valid_predict <- predict(modelfit, validation, type = "class")
modelfit <- rpart(classe ~ ., data=training, method="class")
valid_predict <- predict(modelfit, validation, type = "class")
modelfit1 <- rpart(classe ~ ., data=training, method="class")
valid_predict <- predict(modelfit1, validation, type = "class")
# Plot of the Decision Tree
rpart.plot(modelfit1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
library(rpart.plot) # Decision Tree plotlibrary (randomForest)
install.packages(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(modelfit1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
valid_predict1 <- predict(modelfit1, validation, type = "class")
# Test results on our subTesting data set:
confusionMatrix(valid_predict1, validation$classe)
modelcontrol <- trainControl(method="cv", number=3, verboseIter=FALSE)
modelfit2 <- train(classe ~ ., data=training, method="rf",
trControl=modelcontrol)
modelcontrol <- trainControl(method="cv", number=3, verboseIter=FALSE)
modelfit2 <- train(classe ~ ., data=training, method="rf",
trControl=modelcontrol)
modelfit2$finalModel
valid_predict2 <- predict(modelfit2, newdata=validation)
confusionMatrix(valid_predict2, validation$classe)
ImportantVar <- train(classe ~ ., data = training, method = "rf")
